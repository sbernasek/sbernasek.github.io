{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from os.path import join\n",
    "import pandas as pd\n",
    "\n",
    "from modules.imgur import Client\n",
    "from templating.post import Post\n",
    "\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_hdf(Client.metadata_path, 'data')\n",
    "metadata['album'] = metadata.album.replace('Czech (2019)', 'Czechia (2019)')\n",
    "metadata['album'] = metadata.album.replace('Home (2020)', 'Tahoe (2020)')\n",
    "metadata['album'] = metadata.album.replace('Desert (2020)', 'Palm Springs (2020)')\n",
    "metadata['album'] = metadata.album.replace('Roadtrip (2020)', 'Rocky Mountains (2020)')\n",
    "metadata['album'] = metadata.album.replace('Italy v2 (2019)', 'Italy 2 (2019)')\n",
    "metadata.album = metadata.album.str.rsplit(' ', n=1).apply(lambda x: x[0])\n",
    "metadata = metadata.set_index(['album', 'filename'])\n",
    "metadata = metadata.sort_values('time_shot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GoogleMap API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import googlemaps\n",
    "from datetime import datetime\n",
    "\n",
    "gmaps = googlemaps.Client(key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "responses = {}\n",
    "for idx, record in metadata.iterrows():\n",
    "    if None in record.gps:\n",
    "        continue\n",
    "    \n",
    "    response = gmaps.reverse_geocode(record.gps)\n",
    "    responses[record.path] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# with open('./location_data.json', 'w') as file:\n",
    "#     json.dump(responses, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parse responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('./data/location_data.json', 'r') as file:\n",
    "    responses = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def parse_response(url, response):\n",
    "    \n",
    "    missing_keys = [\n",
    "        'country',\n",
    "        'administrative_area_level_1', \n",
    "        'administrative_area_level_2', \n",
    "        'administrative_area_level_3', \n",
    "        'administrative_area_level_4',\n",
    "        'locality',\n",
    "        'route']\n",
    "\n",
    "    acquired = {'url': url}\n",
    "    for entry in response:\n",
    "        for component in entry['address_components']:\n",
    "            for i, key in enumerate(missing_keys):\n",
    "                if key in component['types']:        \n",
    "                    key = missing_keys.pop(i)                \n",
    "                    acquired[key] = component['short_name']\n",
    "                    \n",
    "    return acquired\n",
    "\n",
    "def fmt_address(record):\n",
    "    \n",
    "    if record.locality is None:\n",
    "        caption = record.country\n",
    "    \n",
    "    elif record.administrative_area_level_1 is None:\n",
    "        caption = '{:s}, {:s}'.format(record.locality, record.country)\n",
    "        \n",
    "    else:\n",
    "        caption = '{:s}, {:s}'.format(record.locality, record.administrative_area_level_1)\n",
    "            \n",
    "    return caption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([parse_response(url, response) for url, response in responses.items()])\n",
    "df[df.isna()] = None\n",
    "df['address'] = df.apply(fmt_address, axis=1)\n",
    "df['city'] = df.locality\n",
    "df['state'] = df.administrative_area_level_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.merge(metadata, df[['url', 'address', 'country', 'state', 'city']], how='left', left_on='path', right_on='url')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shift timestamps and interpolate locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "country_tshifts = {'IT': 9, 'FR': 9, 'GB': 8, 'CZ': 9, 'DE': 9, 'AT': 9, 'SI': 9, 'HR': 9, 'ES': 9, 'MA': 8}\n",
    "state_tshifts = {'CA': 0, 'NV': 0, 'UT': 1, 'WY': 1, 'MT': 1, 'ID': 1}\n",
    "\n",
    "def correct_time(record, fmt='%Y:%m:%d %H:%M:%S'):\n",
    "    time_shot = datetime.strptime(record.time_shot, fmt)\n",
    "    if record.country == 'US':\n",
    "        dt = timedelta(hours=state_tshifts[record.state])\n",
    "    else:\n",
    "        \n",
    "        if record.country not in country_tshifts.keys():\n",
    "            print(record)\n",
    "            raise ValueError\n",
    "        \n",
    "        dt = timedelta(hours=country_tshifts[record.country])\n",
    "    us_time_shot = time_shot - dt\n",
    "    return us_time_shot.strftime(fmt)\n",
    "    \n",
    "def get_us_time(record):\n",
    "    if None in record.gps:\n",
    "        return record.time_shot\n",
    "    else:\n",
    "        us_time_shot = correct_time(record)\n",
    "        return us_time_shot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata['time_shot_pacific'] = metadata.apply(get_us_time, axis=1)\n",
    "metadata = metadata.sort_values(by='time_shot_pacific')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tagged, untagged = metadata[metadata.geotagged], metadata[~metadata.geotagged]\n",
    "idxs = np.searchsorted(tagged.time_shot_pacific.values, untagged.time_shot_pacific.values)\n",
    "for attr in ['city', 'state', 'country', 'address']:\n",
    "    metadata.loc[untagged.index, attr] = tagged.iloc[idxs][attr].values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web",
   "language": "python",
   "name": "web"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
